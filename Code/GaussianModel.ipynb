{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GaussianModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "elcGHU_bb19u"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "df1 = pd.DataFrame(columns= ['id','topic_rank', 'diversity', 'productivity', 'h_index', 'author_rank', 'venur_rank', 'author_MPI', 'author_TPI', 'venur_MPI', 'venur_TPI', 'versatility', 'n-citations'])\r\n",
        "\r\n",
        "#Values adjusted for each feature(Using estimations)\r\n",
        "df1['id'] = np.random.randint(1, 101, 100)\r\n",
        "df1['topic_rank'] = np.random.randint(1, 101, 100)\r\n",
        "df1['diversity'] = np.random.uniform(1, 101, 100)\r\n",
        "df1['productivity'] = np.random.randint(1, 101, 100)\r\n",
        "df1['h_index'] = np.random.uniform(1, 25, 100)\r\n",
        "df1['author_rank'] = np.random.uniform(1, 101, 100)\r\n",
        "df1['venur_rank'] = np.random.randint(1, 101, 100)\r\n",
        "df1['author_MPI'] = np.random.randint(1, 201, 100)\r\n",
        "df1['author_TPI'] = np.random.uniform(1, 301, 100)\r\n",
        "df1['venur_MPI'] = np.random.uniform(1, 301, 100)\r\n",
        "df1['venur_TPI'] = np.random.uniform(1, 401, 100)\r\n",
        "df1['versatility'] = np.random.uniform(1, 101, 100)\r\n",
        "df1['n-citations'] = np.random.randint(1, 101, 100)\r\n",
        "df1\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdUDmI9vb71t"
      },
      "source": [
        "\r\n",
        "#Import all gaussian Processes libraries \r\n",
        "import sklearn.gaussian_process as gp\r\n",
        "from sklearn.datasets import make_classification\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\r\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\r\n",
        "from sklearn.gaussian_process.kernels import RBF\r\n",
        "from sklearn.gaussian_process.kernels import DotProduct\r\n",
        "from sklearn.gaussian_process.kernels import Matern\r\n",
        "from sklearn.gaussian_process.kernels import RationalQuadratic\r\n",
        "from sklearn.gaussian_process.kernels import WhiteKernel\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# define dataset: creates clusters/ list of lists that contain all feature values except n-citatons\r\n",
        "X = df1.iloc[:, 1:12].values \r\n",
        "# the result(n_citation), list of n-citations, assuming n-citations is in 13th column\r\n",
        "y = df1.iloc[:, 12].values\r\n",
        "\r\n",
        "#Split into observtions(X) and results(y) into 80/20 training/test split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size = 0.20, random_state = 0)\r\n",
        "\r\n",
        "#Create gaussian model kernel with the mean(constant at 1) and RBF with lenghscale = 10.0 with lenghscale bounds of (0.001, 1000.0)\r\n",
        "\r\n",
        "##Different covariance kernels being setup with thier respective parameters, Can be selected one at a time\r\n",
        "\r\n",
        "#kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RBF(10.0, (1e-3, 1e3))\r\n",
        "\r\n",
        "#When nu = 0.5 , the Mat√©rn kernel becomes identical to the absolute exponential kernel\r\n",
        "#kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.Matern(1.0, (1e-3, 1e3), nu = 0.5)\r\n",
        "\r\n",
        "#When nu = 1.5 then the exponential function becomes once differentiable \r\n",
        "#kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.Matern(1.0, (1e-3, 1e3), nu = 1.5)\r\n",
        "\r\n",
        "#When nu = 2.5 then the exponential function becomes twice differentiable \r\n",
        "#kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.Matern(1.0, (1e-3, 1e3), nu = 2.5)\r\n",
        "\r\n",
        "#kernel = gp.kernels.ConstantKernel(1.0, (1e-1, 1e3)) * gp.kernels.RationalQuadratic(length_scale=1.0, alpha=1.0, length_scale_bounds=(1e-05, 100000.0), alpha_bounds=(1e-05, 100000.0))\r\n",
        "\r\n",
        "# Where Alpha is variance of independently, identically distributed Gaussian noise form labels(y)\r\n",
        "#Where normalize_y refers to constant mean function:either zero if False or the training data mean if True\r\n",
        "#Where n_restarts_optimizer is multiple restarts of the optimizer with different initializations is used if log log marginal likelihood may not be convex\r\n",
        "model = gp.GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, alpha=0.1, normalize_y=False)\r\n",
        "\r\n",
        "model.fit(X_train, y_train)\r\n",
        "#get hyper parameters of kernel \r\n",
        "params = model.kernel_.get_params()\r\n",
        "params\r\n",
        "\r\n",
        "y_predict, std = model.predict(X_test, return_std=True)\r\n",
        "\r\n",
        "y_predict\r\n",
        "#std\r\n",
        "#MSE\r\n",
        "#MSE = ((y_predict-y_test)**2).mean()\r\n",
        "#MSE\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}