{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "elcGHU_bb19u"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'read_pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-abc1e0088c37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#df1 = pd.DataFrame(columns= ['id','topic_rank', 'diversity', 'productivity', 'h_index', 'author_rank', 'venur_rank', 'author_MPI', 'author_TPI', 'venur_MPI', 'venur_TPI', 'versatility', 'n-citations'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pkl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Data/features_2001.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m#df1 = df1[:1000]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#df1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'read_pkl'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#SETUP DATA\n",
    "#df1 = pd.DataFrame(columns= ['id','topic_rank', 'diversity', 'productivity', 'h_index', 'author_rank', 'venur_rank', 'author_MPI', 'author_TPI', 'venur_MPI', 'venur_TPI', 'versatility', 'n-citations'])\n",
    "\n",
    "df1 = pd.read_pkl(\"/Data/features_2001.pkl\")\n",
    "#df1 = df1[:1000]\n",
    "#df1\n",
    "X = df1.iloc[:,2:12].values \n",
    "# the result(n_citation), list of n-citations, assuming n-citations is in 13th column\n",
    "y = df1.iloc[:, 12].values\n",
    "\n",
    "#y = y.astype('float64') \n",
    "#y = y.reshape(y.shape[0],-1)\n",
    "\n",
    "#y = np.reshape(100,1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size = 0.20, random_state = 0)\n",
    "#X = df1.iloc[:, 1:12].values \n",
    "# the result(n_citation), list of n-citations, assuming n-citations is in 13th column\n",
    "#y = df1.iloc[:, 12].values\n",
    "#df_array = np.asarray(df1)\n",
    "#id = df_array[:,1]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Sx1sDVRS0gS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L4EIHCoPuSlD",
    "outputId": "ef99baf0-487b-43f5-95cf-5647f6519927"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement HistGradientBoostingCLassifier (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for HistGradientBoostingCLassifier\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install HistGradientBoostingCLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "__XlVGuq2N62"
   },
   "outputs": [],
   "source": [
    "#GRADIENT BOOSTING CLASSIFIER\n",
    "from sklearn.datasets import make_hastie_10_2\n",
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting  \n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import GridSearchCV , RepeatedStratifiedKFold , cross_val_predict, cross_val_score\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.metrics import r2_score, confusion_matrix, accuracy_score, mean_absolute_error, mean_squared_error, median_absolute_error\n",
    "\n",
    "#clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "gradientRegressor = GradientBoostingRegressor(max_depth=100,n_estimators=130, learning_rate=0.25)\n",
    "hgbr = HistGradientBoostingRegressor(learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20)\n",
    "\n",
    "#FIT/TRAIN MODELs\n",
    "#lm = LinearRegression().fit(X_train,y_train)\n",
    "#hgbr.fit(X_train,y_train)\n",
    "model = gradientRegressor.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#model = gradientRegressor.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "score = r2_score(y_test,y_pred)\n",
    "MSE =  mean_squared_error (y_test, y_pred)\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n",
    "median_abs_error = median_absolute_error(y_test, y_pred)\n",
    "\n",
    "#y_pred\n",
    "#best score with:  max_depth = 14, 20, 40 , n_estimators = 90 ,100 , learning_rate = \n",
    "#clf.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "AGOmElfHHmBK"
   },
   "outputs": [],
   "source": [
    "#TESTING ACCURACIES\n",
    "MAE = mean_absolute_error(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oWHfGljaB4Bh"
   },
   "outputs": [],
   "source": [
    "#TUNING \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "LR = {'max_depth': [1,2,3,4,5,6,7,8],'n_estimators': [5,25,50,100,150, 200,250,300],'learning_rate':[0.35,0.30,0.25,0.20,0.15, 0.10, 0.1,0.05]}\n",
    "\n",
    "tuning = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=LR, scoring = 'r2')\n",
    "\n",
    "tuning.fit(X_train,y_train)\n",
    "tuning.best_params_, tuning.best_score_\n",
    "#y_pred = tuning.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "n79UBSfGSZPF"
   },
   "outputs": [],
   "source": [
    "#EVALUATION\n",
    "#tuning.cv_results_\n",
    "#y_pred = tuning.predict(X_test)\n",
    "MSE = ((y_pred-y_test)**2).mean()\n",
    "score = r2_score(y_pred,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QkDMV_-wAAuX",
    "outputId": "4f285dcb-7a2b-466d-d53c-07f0c6ead394"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.70054981e+00,  2.62324381e+01,  2.06659634e+01,  7.99994961e+00,\n",
       "        4.78438565e+00,  5.75664413e+00,  2.52100315e+01,  2.05024202e+02,\n",
       "       -7.47324953e-05,  1.85875303e+01,  9.99996692e-01,  9.07661991e+00,\n",
       "        2.99927136e+00,  2.55115061e+01,  9.99940825e-01])"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = y_pred[:25]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bRP2cghSTzPy",
    "outputId": "dae15526-ae87-40d9-cdb6-f4009981c5f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,  27,   2,   9,   9,  11,  25, 118,   0,  33,   1,   6,   1,\n",
       "        58,   1])"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test[:25]\n",
    "y_test"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "GradientBoostingModel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
