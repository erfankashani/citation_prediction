{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GradientBoostingModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "elcGHU_bb19u"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv \n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#SETUP DATA\n",
        "#df1 = pd.DataFrame(columns= ['id','topic_rank', 'diversity', 'productivity', 'h_index', 'author_rank', 'venur_rank', 'author_MPI', 'author_TPI', 'venur_MPI', 'venur_TPI', 'versatility', 'n-citations'])\n",
        "\n",
        "df1 = pd.read_csv(\"/content/features_2001.csv\")\n",
        "#df1 = df1[:1000]\n",
        "#df1\n",
        "X = df1.iloc[:,2:12].values \n",
        "# the result(n_citation), list of n-citations, assuming n-citations is in 13th column\n",
        "y = df1.iloc[:, 12].values\n",
        "\n",
        "#y = y.astype('float64') \n",
        "#y = y.reshape(y.shape[0],-1)\n",
        "\n",
        "#y = np.reshape(100,1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y , test_size = 0.20, random_state = 0)\n",
        "#X = df1.iloc[:, 1:12].values \n",
        "# the result(n_citation), list of n-citations, assuming n-citations is in 13th column\n",
        "#y = df1.iloc[:, 12].values\n",
        "#df_array = np.asarray(df1)\n",
        "#id = df_array[:,1]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Sx1sDVRS0gS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4EIHCoPuSlD",
        "outputId": "ef99baf0-487b-43f5-95cf-5647f6519927"
      },
      "source": [
        "!pip install HistGradientBoostingCLassifier"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement HistGradientBoostingCLassifier (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for HistGradientBoostingCLassifier\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__XlVGuq2N62"
      },
      "source": [
        "#GRADIENT BOOSTING CLASSIFIER\n",
        "from sklearn.datasets import make_hastie_10_2\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.experimental import enable_hist_gradient_boosting  \n",
        "from sklearn.ensemble import HistGradientBoostingClassifier, HistGradientBoostingRegressor\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import GridSearchCV , RepeatedStratifiedKFold , cross_val_predict, cross_val_score\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.datasets import load_boston\n",
        "from sklearn.metrics import r2_score, confusion_matrix, accuracy_score, mean_absolute_error, mean_squared_error, median_absolute_error\n",
        "\n",
        "#clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
        "gradientRegressor = GradientBoostingRegressor(max_depth=100,n_estimators=130, learning_rate=0.25)\n",
        "hgbr = HistGradientBoostingRegressor(learning_rate=0.1, max_iter=100, max_leaf_nodes=31, min_samples_leaf=20)\n",
        "\n",
        "#FIT/TRAIN MODELs\n",
        "#lm = LinearRegression().fit(X_train,y_train)\n",
        "#hgbr.fit(X_train,y_train)\n",
        "model = gradientRegressor.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "#model = gradientRegressor.fit(X_train,y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "score = r2_score(y_test,y_pred)\n",
        "MSE =  mean_squared_error (y_test, y_pred)\n",
        "MAE = mean_absolute_error(y_test, y_pred)\n",
        "median_abs_error = median_absolute_error(y_test, y_pred)\n",
        "\n",
        "#y_pred\n",
        "#best score with:  max_depth = 14, 20, 40 , n_estimators = 90 ,100 , learning_rate = \n",
        "#clf.score(X_test, y_test)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGOmElfHHmBK"
      },
      "source": [
        "#TESTING ACCURACIES\n",
        "MAE = mean_absolute_error(y_test, y_pred)\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWHfGljaB4Bh"
      },
      "source": [
        "#TUNING \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "LR = {'max_depth': [1,2,3,4,5,6,7,8],'n_estimators': [5,25,50,100,150, 200,250,300],'learning_rate':[0.35,0.30,0.25,0.20,0.15, 0.10, 0.1,0.05]}\n",
        "\n",
        "tuning = GridSearchCV(estimator=GradientBoostingRegressor(), param_grid=LR, scoring = 'r2')\n",
        "\n",
        "tuning.fit(X_train,y_train)\n",
        "tuning.best_params_, tuning.best_score_\n",
        "#y_pred = tuning.predict(X_test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n79UBSfGSZPF"
      },
      "source": [
        "#EVALUATION\n",
        "#tuning.cv_results_\n",
        "#y_pred = tuning.predict(X_test)\n",
        "MSE = ((y_pred-y_test)**2).mean()\n",
        "score = r2_score(y_pred,y_test)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkDMV_-wAAuX",
        "outputId": "4f285dcb-7a2b-466d-d53c-07f0c6ead394"
      },
      "source": [
        "y_pred = y_pred[:25]\n",
        "y_pred"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 3.70054981e+00,  2.62324381e+01,  2.06659634e+01,  7.99994961e+00,\n",
              "        4.78438565e+00,  5.75664413e+00,  2.52100315e+01,  2.05024202e+02,\n",
              "       -7.47324953e-05,  1.85875303e+01,  9.99996692e-01,  9.07661991e+00,\n",
              "        2.99927136e+00,  2.55115061e+01,  9.99940825e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRP2cghSTzPy",
        "outputId": "dae15526-ae87-40d9-cdb6-f4009981c5f6"
      },
      "source": [
        "y_test = y_test[:25]\n",
        "y_test"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  5,  27,   2,   9,   9,  11,  25, 118,   0,  33,   1,   6,   1,\n",
              "        58,   1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    }
  ]
}